---
title: 'AI Needs the Humanities'
date: 2024-04-13

# permalink: /posts/2012/08/blog-post-4/

#tags:
#  - humanities
#  - ai
#  - category2
---
zachary k stine  
started: 2024-04-13    
updated:  

# AI Needs the Humanities
<br><br>
Earlier in the year, I gave a presentation with this title at a local bioinformatics conference. The session was on AI and ethics. My basic point was that AI makes it clear that it is in humanity's best interests to support the kind of knowledge-production and skills training which happens to be done in a large-scale, efficient manner through the so-called humanities. The discourse around the broader values of humanities programs relative to their economic or scientific value, which by their nature tend to turn such broader values into measurable qualities, has always struck me as fraught. The bad takes are endless and it's honestly just kind of hard to watch remarkable scholars have to endlessly justify their existence. Part of the problem is that one's ability to appreciate the hard-to-articulate value of such skills depends on having gained exactly those skills. It's not surprising that there are people who see something like a scam in all this; certainly not something worth expending our limited resources on. *What are we getting out of all this navel-gazing? What has a scholar of classical Chinese thought or of games ever done that's put food on my table?*
<br>  
Another tedious discursive faultline I find myself wishing (and failing) to avoid is that which is centered around so-called artificial intelligence. There's a funhouse mirror effect of the just-mentioned discourse present here: The salient question is how to evaluate the value of the spectrum of tools that people often mean by AI. Caricatures of the pro-AI (which sadly are what proliferate in dense social-information networks) might say that it's easy to evalute the value of such tools: there's metrics for that! When a metric gets bigger (or perhaps smaller), that means better—it's math! Or that the consistency of what such tools distill and remix with our expectations of what natural information manipulation looks like indicates, qualitatively and beyond what we can say in numbers, what it means to be better. Even those of us with a basic capacity for critical thinking can spot what's missing, what is necessary yet out of the boundaries of the system under discussion: *Yes, but what is the context in which such ends can be said to be valuable or not? What does it mean for my quality of life when that number is able to get bigger or smaller? Why should we assume it is good for a formal system to decompose and recompose the things we have made in such a way that feels like the products of humans?*  
<br>  

Missing this line of questioning really ought to be inexcusable for those of us who study computing given the role played by Gödel's incompleteness theorems in our discipline's founding myths (see Petzold's The Annotated Turing as a riveting telling of this story). The parable Gödel tells us, deeply and achingly beautiful, is that anything can be unambigously distinguished, said to be true or false, within an unambiguously described system *except for 
<br>


## Wonder, awe, and the inarticulable
<br>
[summarize the relevant arguments that I see De Cruz and Nguyen making]



You can have many headings
======

Aren't headings cool?
------

